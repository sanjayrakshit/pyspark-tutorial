{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7e5e50-12d6-43e7-abe3-bce8f424a3e3",
   "metadata": {},
   "source": [
    "## 1. Basics of pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ede2b53-a5a2-406c-b6cd-5c0f5703b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b344f52-172f-4486-9c93-3fd02cdc98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_root = Path('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b93d94-8e57-4c4e-8e30-e55d5ce0bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(content_root.joinpath('data', 'dummydata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d54bc5-0707-4f1f-8174-aa444f8d20c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sanjay</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rakshit</td>\n",
       "      <td>26</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medha</td>\n",
       "      <td>23</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age  Height\n",
       "0   Sanjay   26     158\n",
       "1  Rakshit   26     160\n",
       "2    Medha   23     150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388e38ae-fe13-457f-9b2b-62c8fa4d07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77cc66f4-6c3d-460e-9801-448fb57161d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ce18f-3bef-4fa6-9037-d36fe236b578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x15fec9190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940b79ba-2cba-40d5-8cc8-1d08dc9de47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/12 20:13:16 WARN Utils: Your hostname, Sanjays-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.37 instead (on interface en0)\n",
      "21/09/12 20:13:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/09/12 20:13:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5528b04b-ea33-4fc4-b40e-aeeb676b7124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.37:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x160013730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1d897f-9d25-414b-8983-b291518b0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read\\\n",
    ".option('header', 'true')\\\n",
    ".csv(str(content_root.joinpath('data', 'dummydata.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea59988-405f-4085-a451-3f9115062107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string, Height: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ade5ca4-c069-4a81-a258-3bf7ce7202e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+\n",
      "|   Name|Age|Height|\n",
      "+-------+---+------+\n",
      "| Sanjay| 26|   158|\n",
      "|Rakshit| 26|   160|\n",
      "|  Medha| 23|   150|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e4e3469-19e5-4435-8d86-172af0bbdaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4787fd6d-7aa4-4e15-930b-726cf89de188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Sanjay', Age='26', Height='158'),\n",
       " Row(Name='Rakshit', Age='26', Height='160'),\n",
       " Row(Name='Medha', Age='23', Height='150')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ab9ec7-9758-4fe3-8f09-13df065b9a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Height: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6445b1-62f1-473c-ac20-7da8816e1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the dataset\n",
    "\n",
    "df_spark = spark.read.option('header', 'true').csv('../data/dummydata.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e27a6249-fbd2-4fb9-ae95-90e14e2ef32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Height: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaf35515-6fb9-47d0-9e6f-27fcaaef6e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "| Sanjay|\n",
      "|Rakshit|\n",
      "|  Medha|\n",
      "+-------+\n",
      "\n",
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "| Sanjay| 26|\n",
      "|Rakshit| 26|\n",
      "|  Medha| 23|\n",
      "+-------+---+\n",
      "\n",
      "+-------+---+------+\n",
      "|   Name|Age|Height|\n",
      "+-------+---+------+\n",
      "| Sanjay| 26|   158|\n",
      "|Rakshit| 26|   160|\n",
      "|  Medha| 23|   150|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting a column\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "df_spark.select('Name').show()\n",
    "\n",
    "df_spark.select('Name', 'Age').show()\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "428bc00e-32f1-47e0-92a0-d372cc1d2b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Height', 'int')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datatypes\n",
    "\n",
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd21af07-d666-4ffb-9eda-c8301df2ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+\n",
      "|summary|  Name|               Age|           Height|\n",
      "+-------+------+------------------+-----------------+\n",
      "|  count|     3|                 3|                3|\n",
      "|   mean|  null|              25.0|            156.0|\n",
      "| stddev|  null|1.7320508075688772|5.291502622129181|\n",
      "|    min| Medha|                23|              150|\n",
      "|    max|Sanjay|                26|              160|\n",
      "+-------+------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe\n",
    "\n",
    "df_spark.describe()\n",
    "\n",
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f66c5a33-253c-4291-88c3-e776cde82369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+--------------+\n",
      "|   Name|Age|Height|Age after 10yr|\n",
      "+-------+---+------+--------------+\n",
      "| Sanjay| 26|   158|            36|\n",
      "|Rakshit| 26|   160|            36|\n",
      "|  Medha| 23|   150|            33|\n",
      "+-------+---+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding cols & dropping cols\n",
    "\n",
    "df_spark = df_spark.withColumn('Age after 10yr', df_spark['Age']+10)\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e88d426-fe1c-44bd-9b75-2b0b61640556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+\n",
      "|   Name|Age|Height|\n",
      "+-------+---+------+\n",
      "| Sanjay| 26|   158|\n",
      "|Rakshit| 26|   160|\n",
      "|  Medha| 23|   150|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now dropping\n",
    "\n",
    "df_spark = df_spark.drop('Age after 10yr')\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d17e7d56-b637-4dbc-be76-2edc95c8d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column\n",
    "\n",
    "df_spark = df_spark.withColumnRenamed('Height', 'Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28fc786b-f1bc-4aa4-8b3b-3f50e0b0b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+\n",
      "|   Name|Age|Weight|\n",
      "+-------+---+------+\n",
      "| Sanjay| 26|   158|\n",
      "|Rakshit| 26|   160|\n",
      "|  Medha| 23|   150|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7246dd4-464e-4b77-ad19-9b3a672d7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2efe89-7cbe-47ee-b186-e1df7bd6c6e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab262b2-8ffd-44af-b400-5bd2809862dd",
   "metadata": {},
   "source": [
    "## 2. Some more manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf832986-8b78-4532-9af0-daed863da7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9ef8f0c-8d93-4522-a634-5b66d18b0517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+-------+-----+\n",
      "|      Name|Age|Experience|Passout|Score|\n",
      "+----------+---+----------+-------+-----+\n",
      "|    Sanjay| 26|       3.5|   2017|  0.7|\n",
      "|     Medha| 23|       0.6|   2020|  0.7|\n",
      "|Steve Jobs|100|      null|   null|  1.0|\n",
      "| Elon Musk| 50|      null|   null|  1.0|\n",
      "|     Montu| 16|      null|   2025|  0.1|\n",
      "+----------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv(\n",
    "    '../data/dummydata2.csv',\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "448685fb-66fe-4621-9af7-cc848817460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      " |-- Passout: integer (nullable = true)\n",
      " |-- Score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cc3329a-38a9-44fb-9179-b3481e069359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-------+-----+\n",
      "|  Name|Age|Experience|Passout|Score|\n",
      "+------+---+----------+-------+-----+\n",
      "|Sanjay| 26|       3.5|   2017|  0.7|\n",
      "| Medha| 23|       0.6|   2020|  0.7|\n",
      "+------+---+----------+-------+-----+\n",
      "\n",
      "+----------+---+----------+-------+-----+\n",
      "|      Name|Age|Experience|Passout|Score|\n",
      "+----------+---+----------+-------+-----+\n",
      "|    Sanjay| 26|       3.5|   2017|  0.7|\n",
      "|     Medha| 23|       0.6|   2020|  0.7|\n",
      "|Steve Jobs|100|      null|   null|  1.0|\n",
      "| Elon Musk| 50|      null|   null|  1.0|\n",
      "|     Montu| 16|      null|   2025|  0.1|\n",
      "+----------+---+----------+-------+-----+\n",
      "\n",
      "+------+---+----------+-------+-----+\n",
      "|  Name|Age|Experience|Passout|Score|\n",
      "+------+---+----------+-------+-----+\n",
      "|Sanjay| 26|       3.5|   2017|  0.7|\n",
      "| Medha| 23|       0.6|   2020|  0.7|\n",
      "+------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing anything that is na\n",
    "\n",
    "df_spark.na.drop().show()\n",
    "\n",
    "df_spark.na.drop(how='all').show()\n",
    "\n",
    "df_spark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91e7e278-a24a-4cc2-ba34-4f3b5bb66df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-------+-----+\n",
      "|  Name|Age|Experience|Passout|Score|\n",
      "+------+---+----------+-------+-----+\n",
      "|Sanjay| 26|       3.5|   2017|  0.7|\n",
      "| Medha| 23|       0.6|   2020|  0.7|\n",
      "| Montu| 16|      null|   2025|  0.1|\n",
      "+------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop with threshold\n",
    "\n",
    "df_spark.na.drop(how='any', \n",
    "                 thresh=4 # Atleast 4 non-null values should be present\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2dcf516-a1b7-45c6-8df4-b1497a508040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-------+-----+\n",
      "|  Name|Age|Experience|Passout|Score|\n",
      "+------+---+----------+-------+-----+\n",
      "|Sanjay| 26|       3.5|   2017|  0.7|\n",
      "| Medha| 23|       0.6|   2020|  0.7|\n",
      "| Montu| 16|      null|   2025|  0.1|\n",
      "+------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset in drop\n",
    "\n",
    "df_spark.na.drop(subset='Passout' # Deletes all null values in the column 'Passout'\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "265074de-2c1a-448f-8365-53f180f5834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+-------+-----+\n",
      "|      Name|Age|Experience|Passout|Score|\n",
      "+----------+---+----------+-------+-----+\n",
      "|    Sanjay| 26|       3.5|   2017|  0.7|\n",
      "|     Medha| 23|       0.6|   2020|  0.7|\n",
      "|Steve Jobs|100|       0.0|   null|  1.0|\n",
      "| Elon Musk| 50|       0.0|   null|  1.0|\n",
      "|     Montu| 16|       0.0|   2025|  0.1|\n",
      "+----------+---+----------+-------+-----+\n",
      "\n",
      "+----------+---+----------+-------+-----+\n",
      "|      Name|Age|Experience|Passout|Score|\n",
      "+----------+---+----------+-------+-----+\n",
      "|    Sanjay| 26|       3.5|   2017|  0.7|\n",
      "|     Medha| 23|       0.6|   2020|  0.7|\n",
      "|Steve Jobs|100|     100.0|    100|  1.0|\n",
      "| Elon Musk| 50|     100.0|    100|  1.0|\n",
      "|     Montu| 16|     100.0|   2025|  0.1|\n",
      "+----------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill na\n",
    "\n",
    "df_spark.na.fill(0, # puts 0 wherever there is null in 'Experience'\n",
    "                'Experience'\n",
    "                ).show()\n",
    "\n",
    "\n",
    "df_spark.na.fill(100, # puts 100 wherever there is null in dataframe which has integer/float dtypes\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b95c1d1-9cf9-4083-b7d3-bb3a91325f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with mean\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['Experience', 'Passout'],\n",
    "    outputCols=[f'{i}_mean' for i in ['Experience', 'Passout']]\n",
    "    ).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9274ec6f-ffc1-4988-b3c4-53400f15dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+-------+-----+---------------+------------+\n",
      "|      Name|Age|Experience|Passout|Score|Experience_mean|Passout_mean|\n",
      "+----------+---+----------+-------+-----+---------------+------------+\n",
      "|    Sanjay| 26|       3.5|   2017|  0.7|            3.5|        2017|\n",
      "|     Medha| 23|       0.6|   2020|  0.7|            0.6|        2020|\n",
      "|Steve Jobs|100|      null|   null|  1.0|           2.05|        2020|\n",
      "| Elon Musk| 50|      null|   null|  1.0|           2.05|        2020|\n",
      "|     Montu| 16|      null|   2025|  0.1|           2.05|        2025|\n",
      "+----------+---+----------+-------+-----+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_spark).transform(df_spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c85d7239-7bf7-4e5c-8d43-2cef2e11280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b80ce-e016-4834-a3e1-66d8342c1fa1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43159c48-178e-49e2-b5a3-4ec5a4010dfc",
   "metadata": {},
   "source": [
    "## 3. Filter and few additional operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09c0c527-8045-4d6f-8b9c-ef08812a098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf43cb71-bee0-4003-8e01-90643b551945",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "596330f2-cb1d-41e4-9c75-eb7a2e41a3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+-------+-----+\n",
      "|      Name|Age|Experience|Passout|Score|\n",
      "+----------+---+----------+-------+-----+\n",
      "|    Sanjay| 26|       3.5|   2017|  0.7|\n",
      "|     Medha| 23|       0.6|   2020|  0.7|\n",
      "|Steve Jobs|100|      null|   null|  1.0|\n",
      "| Elon Musk| 50|      null|   null|  1.0|\n",
      "|     Montu| 16|      null|   2025|  0.1|\n",
      "+----------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('../data/dummydata2.csv',\n",
    "                          header=True,\n",
    "                          inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a8f8fd8-7905-46ce-b727-0d1b16233ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+-------+-----+\n",
      "| Name|Age|Experience|Passout|Score|\n",
      "+-----+---+----------+-------+-----+\n",
      "|Montu| 16|      null|   2025|  0.1|\n",
      "+-----+---+----------+-------+-----+\n",
      "\n",
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|Montu| 16|\n",
      "+-----+---+\n",
      "\n",
      "+----------+---+----------+-------+-----+\n",
      "|      Name|Age|Experience|Passout|Score|\n",
      "+----------+---+----------+-------+-----+\n",
      "|Steve Jobs|100|      null|   null|  1.0|\n",
      "| Elon Musk| 50|      null|   null|  1.0|\n",
      "+----------+---+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "\n",
    "df_spark.filter('Score<=0.5').show()\n",
    "\n",
    "df_spark.filter('Score<=0.5').select(['Name', 'Age']).show()\n",
    "\n",
    "df_spark.filter((df_spark['Score']>=0.5) & \n",
    "                 (df_spark['Age']>=30)\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d86a4cae-9bbf-4a4b-876b-46e13371d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cf0c2-c18d-482a-9301-a083d30a0c85",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fe392-f17c-4b51-b20c-460b7f10aad8",
   "metadata": {},
   "source": [
    "## 4. Groupby and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baec06fd-d78a-4ac2-bd8f-f0ac495e003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('dfs').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd316739-7acc-4f8c-b4f7-f53c15f1d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      Name|Occupation|Experience|\n",
      "+----------+----------+----------+\n",
      "|    Sanjay|  Software|       3.5|\n",
      "|     Medha| Marketing|       0.6|\n",
      "| Elon Musk|  Software|      40.0|\n",
      "|Bill Gates|  Software|      60.0|\n",
      "|Other Basu| Marketing|     100.0|\n",
      "|  Person 1|     Sales|       5.0|\n",
      "|  Person A|     Admin|      10.0|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('../data/dummydata3.csv',\n",
    "                         header=True,\n",
    "                         inferSchema=True)\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d8d6740-f693-4253-a5d6-464e34e3ba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9b6783a-2da9-4fdc-a1d3-687313a491ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Occupation', 'string'), ('Experience', 'double')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5abbf2f1-fe48-49b8-8174-d04717c9cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|Occupation|sum(Experience)|\n",
      "+----------+---------------+\n",
      "|     Sales|            5.0|\n",
      "|     Admin|           10.0|\n",
      "| Marketing|          100.6|\n",
      "|  Software|          103.5|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Occupation|count|\n",
      "+----------+-----+\n",
      "|     Sales|    1|\n",
      "|     Admin|    1|\n",
      "| Marketing|    2|\n",
      "|  Software|    3|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+---------------+\n",
      "|Occupation|max(Experience)|\n",
      "+----------+---------------+\n",
      "|     Sales|            5.0|\n",
      "|     Admin|           10.0|\n",
      "| Marketing|          100.0|\n",
      "|  Software|           60.0|\n",
      "+----------+---------------+\n",
      "\n",
      "+----------+---------------+\n",
      "|Occupation|min(Experience)|\n",
      "+----------+---------------+\n",
      "|     Sales|            5.0|\n",
      "|     Admin|           10.0|\n",
      "| Marketing|            0.6|\n",
      "|  Software|            3.5|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby\n",
    "\n",
    "df_spark.groupBy('Occupation').sum('Experience').show() # the sum of experience per group\n",
    "\n",
    "df_spark.groupBy('Occupation').count().show() # The count of entries per group\n",
    "\n",
    "df_spark.groupBy('Occupation').max('Experience').show() # The max value of experience per group\n",
    "\n",
    "df_spark.groupBy('Occupation').min('Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f00c26f-b2ea-4c44-9389-c469773848c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e0748-64ef-4304-a452-0ebc59b99580",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d488932-07c1-4c15-ad47-a022fc0e3662",
   "metadata": {},
   "source": [
    "## 5. MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a0b3e5f-ebf8-4790-be17-d32be15342d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('mllib').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07882f21-2fce-44fd-90ce-271ce71d2ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|   Sanjay| 31|        10|300000|\n",
      "|Sudhanshu| 30|         8|250000|\n",
      "|    Sunny| 29|         4|200000|\n",
      "|     Paul| 24|         3|200000|\n",
      "|   Harsha| 21|         1|150000|\n",
      "|  Shubham| 23|         2|180000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('../data/mllibdata.csv',\n",
    "                     header=True,\n",
    "                     inferSchema=True)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89274e5f-94a2-410d-b4a2-de353affeb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca218ac1-b743-4ce2-94f8-4b3c122065e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need feature assembler in pyspark to create the features to be used by our algorithm\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols=['Age','Experience'],\n",
    "                                  outputCol='independent_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce905c80-8140-4349-ade8-a2ff4e78ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+-------------------+\n",
      "|     Name|Age|Experience|Salary|independent_feature|\n",
      "+---------+---+----------+------+-------------------+\n",
      "|   Sanjay| 31|        10|300000|        [31.0,10.0]|\n",
      "|Sudhanshu| 30|         8|250000|         [30.0,8.0]|\n",
      "|    Sunny| 29|         4|200000|         [29.0,4.0]|\n",
      "|     Paul| 24|         3|200000|         [24.0,3.0]|\n",
      "|   Harsha| 21|         1|150000|         [21.0,1.0]|\n",
      "|  Shubham| 23|         2|180000|         [23.0,2.0]|\n",
      "+---------+---+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = featureassembler.transform(data)\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3d00ebd-5e51-476a-9335-d44a06a58e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|independent_feature|Salary|\n",
      "+-------------------+------+\n",
      "|        [31.0,10.0]|300000|\n",
      "|         [30.0,8.0]|250000|\n",
      "|         [29.0,4.0]|200000|\n",
      "|         [24.0,3.0]|200000|\n",
      "|         [21.0,1.0]|150000|\n",
      "|         [23.0,2.0]|180000|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = output.select('independent_feature', 'Salary')\n",
    "\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01d82af4-68dd-483c-84e6-eff779dc15fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|independent_feature|Salary|\n",
      "+-------------------+------+\n",
      "|         [23.0,2.0]|180000|\n",
      "|         [24.0,3.0]|200000|\n",
      "|         [29.0,4.0]|200000|\n",
      "|        [31.0,10.0]|300000|\n",
      "+-------------------+------+\n",
      "\n",
      "+-------------------+------+\n",
      "|independent_feature|Salary|\n",
      "+-------------------+------+\n",
      "|         [21.0,1.0]|150000|\n",
      "|         [30.0,8.0]|250000|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.60, 0.40],\n",
    "                                               seed=21)\n",
    "train_data.show()\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d2896d2-d052-4496-b1a7-fdc2513c291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/12 20:13:46 WARN Instrumentation: [d7411ad2] regParam is zero, which might cause numerical instability and overfitting.\n",
      "21/09/12 20:13:46 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/09/12 20:13:46 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "21/09/12 20:13:46 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "21/09/12 20:13:46 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "# Lets do linear regression\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regr = LinearRegression(featuresCol='independent_feature',\n",
    "                       labelCol='Salary')\n",
    "regr = regr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4dba941d-1e19-46f0-87bf-bac47dc94c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-2982.4561, 17719.2982])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60e08379-d3fa-49cf-9a8b-27ea618119ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------------------+\n",
      "|independent_feature|Salary|        prediction|\n",
      "+-------------------+------+------------------+\n",
      "|         [21.0,1.0]|150000|170701.75438596515|\n",
      "|         [30.0,8.0]|250000| 267894.7368421052|\n",
      "+-------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_res = regr.evaluate(test_data)\n",
    "\n",
    "pred_res.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4829b71b-0f3c-42be-a8cf-7ec47120a25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19298.245614035186, 19349.214988017284)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res.meanAbsoluteError, pred_res.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f5bdb-f831-4521-9a22-167e99618a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('def-py-env-intel': venv)",
   "language": "python",
   "name": "python395jvsc74a57bd00bbf3d946b9d8491a062ae884d63eeb502793ff2388e3f8dfecc11c0c5422071"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
